{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dlrgNnJqzy1I"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn  # 뉴럴네트워크 함수\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"code","source":["# torch는 다 벡터 값이다."],"metadata":{"id":"ews8sCfRSZZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCtjm1Wpzy1K"},"outputs":[],"source":["## 딥러닝 모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGvgiZoRzy1K"},"outputs":[],"source":["# 뉴럴네트워크\n","class NeuralNet(nn.Module): # 뉴럴네트워크 만들때 클래스에 nn.Module을 만드는게 국룰이다. \n","    def __init__(self, input_size, hidden_size, num_classes):  # 초기값 설정하는 것. self뒤에 것들은 class에 input으로 넣을 것을 적어주는 것이다. 그리고 num_classes는 최종 출력값이다. \n","        super(NeuralNet, self).__init__()  # 이거는 왜 하는 걸까?\n","        self.mlp1 = nn.Linear(input_size, hidden_size) # 첫번째 layer FC이다.\n","        self.relu = nn.ReLU()  # 활성함수 지정\n","        self.mlp2 = nn.Linear(hidden_size, num_classes) # 두번째 layer FC이다. \n","        self.softmax = nn.Softmax(dim=1) # 분류작업 하기위해 소프트맥스로 확률값을 취하기 위해 쓴다. \n","    def forward(self, x):  # 출력값 설정\n","        out = self.mlp1(x)\n","        out = self.relu(out)\n","        out = self.mlp2(out)\n","        out = self.softmax(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPQFr4Z-zy1L","executionInfo":{"status":"ok","timestamp":1670589078098,"user_tz":-540,"elapsed":4,"user":{"displayName":"김재승","userId":"03874947516604107485"}},"outputId":"a1fac35c-2213-471d-8fdb-fea2046760b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hB5NK-Itzy1L","executionInfo":{"status":"ok","timestamp":1670589084840,"user_tz":-540,"elapsed":298,"user":{"displayName":"김재승","userId":"03874947516604107485"}},"outputId":"36d911da-be07-41b1-d394-6831753428aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNet(\n","  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n","  (relu): ReLU()\n","  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["input_size = 28*28*1 # MNIST 이미지 크기\n","hidden_size = 100 # hyper parameter\n","num_classes = 10 # 총 MNIST의 class 갯수\n","\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)   # .to(device)는 cpu 일때 안써도 된다.\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SciwF4Azy1M","outputId":"b181885b-356c-4291-d34e-07689d9ae984"},"outputs":[{"name":"stdout","output_type":"stream","text":["data: torch.Size([1, 784])\n","----------------------------------------\n","pred: tensor([[0.0907, 0.0983, 0.1043, 0.0927, 0.0947, 0.1213, 0.0872, 0.1213, 0.0953,\n","         0.0943]], grad_fn=<SoftmaxBackward>)\n","----------------------------------------\n","y hat: tensor([7])\n"]}],"source":["data = torch.rand(1, 28*28).to(device)\n","print('data:',data.shape)\n","print('-'*40)\n","\n","pred = model(data)\n","print('pred:',pred)\n","print('-'*40)\n","\n","y_hat = pred.argmax(1) # 값이 제일 높은거 하나 뽑기\n","print('y hat:',y_hat)"]},{"cell_type":"markdown","metadata":{"id":"NI43pphczy1M"},"source":["### nn.Linear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFCr0WLyzy1N"},"outputs":[],"source":["x = torch.randn(3,28,28)  # 3은 데이터의 갯수이다. 28x28 이미지크기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7lRkBYpfzy1O","outputId":"00408a66-3655-42d9-97b0-0f2d806a1b52"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_after_fc: torch.Size([3, 100])\n"]}],"source":["fc_layer = nn.Linear(in_features=28*28, out_features=100)\n","x_after_fc = fc_layer(x.reshape(-1,28*28))\n","print('x_after_fc:',x_after_fc.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaUnCUjRzy1O","outputId":"a3cc6914-e648-4202-caa0-87f53d6b165a"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 784])\n","x_after_fc: torch.Size([3, 100])\n"]}],"source":["# nn.Flatten : x.reshape(-1,28*28)과 같은 역할\n","# 28x28 사이즈의 이미지를 784 픽셀 값을 갖는 배열로 변환\n","\n","flatten = nn.Flatten()\n","flat_x = flatten(x)\n","print(flat_x.shape)\n","\n","fc_layer = nn.Linear(in_features=28*28, out_features=100)\n","x_after_fc = fc_layer(flat_x)\n","print('x_after_fc:',x_after_fc.shape)"]},{"cell_type":"markdown","metadata":{"id":"L5kU4IXAzy1P"},"source":["### nn.ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JErtlUHqzy1P"},"outputs":[],"source":["x = torch.randn(3,28,28)  # 3은 데이터 갯수이고, 28x28 행렬로 이루어져있다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DRwH9Bvzy1P","executionInfo":{"status":"ok","timestamp":1670607624129,"user_tz":-540,"elapsed":298,"user":{"displayName":"김재승","userId":"03874947516604107485"}},"outputId":"3c764818-599f-44a5-ffbd-42db2a5a3114"},"outputs":[{"output_type":"stream","name":"stdout","text":["before_relu : tensor([ 1.3258, -1.0004, -1.2106, -0.1239,  1.1380, -0.4152, -0.5813, -0.3026,\n","        -0.4818, -1.3361,  1.8368,  1.0988,  0.6355, -0.9385, -0.1672, -0.4743,\n","        -1.5085,  0.6050,  1.1130,  0.4190, -0.5781, -0.1485,  0.8649, -1.6233,\n","         0.8800, -0.7283, -1.7633,  0.1791]) torch.Size([28])\n","----------------------------------------------------------------------------------------------------\n","after_relu : tensor([1.3258, 0.0000, 0.0000, 0.0000, 1.1380, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 1.8368, 1.0988, 0.6355, 0.0000, 0.0000, 0.0000, 0.0000, 0.6050,\n","        1.1130, 0.4190, 0.0000, 0.0000, 0.8649, 0.0000, 0.8800, 0.0000, 0.0000,\n","        0.1791]) torch.Size([28])\n"]}],"source":["before_relu = x[0][0]\n","print('before_relu :', before_relu, before_relu.shape)\n","print('-'*100)\n","\n","relu = nn.ReLU()\n","after_relu = relu(before_relu)\n","print('after_relu :', after_relu, after_relu.shape)"]},{"cell_type":"markdown","metadata":{"id":"I6oqESTSzy1P"},"source":["### Softmax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrhKxpZFzy1Q","outputId":"7c1b4660-46df-4c25-dcdb-66032d516c05"},"outputs":[{"data":{"text/plain":["tensor([[ 0.1237, -0.7806, -1.1575, -1.2096, -0.0131,  0.2782,  0.8502,  1.2090,\n","         -0.0721, -1.8007]])"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(1,10)  # \n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rf0o9v9Zzy1Q"},"outputs":[],"source":["softmax = nn.Softmax(dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWwMfaJHzy1Q","outputId":"697b4953-5a79-4b71-fafb-54213bc98ed1"},"outputs":[{"name":"stdout","output_type":"stream","text":["pred: tensor([[0.1002, 0.0406, 0.0278, 0.0264, 0.0874, 0.1169, 0.2072, 0.2966, 0.0824,\n","         0.0146]])\n","sum of pred: tensor(1.)\n"]}],"source":["pred = softmax(x)\n","print('pred:', pred)\n","print('sum of pred:',pred.sum())"]},{"cell_type":"markdown","metadata":{"id":"X6qRt4r6zy1R"},"source":["### nn.Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cq0XepdCzy1R"},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.mlp1 = nn.Linear(input_size, hidden_size) \n","        self.relu = nn.ReLU()\n","        self.mlp2 = nn.Linear(hidden_size, num_classes)  \n","        self.softmax = nn.Softmax(dim=1)  # 1차원에 대해서 적용\n","    def forward(self, x):\n","        out = self.mlp1(x)\n","        out = self.relu(out)\n","        out = self.mlp2(out)\n","        out = self.softmax(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKwm6hznzy1R","outputId":"ba0f9fde-8930-4285-ea3a-7d600604c0b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuralNet(\n","  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n","  (relu): ReLU()\n","  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["input_size = 28*28*1 # MNIST 이미지 크기\n","hidden_size = 100 # hyper parameter\n","num_classes = 10 # 총 class 수\n","\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JI4aJPhlzy1S"},"outputs":[],"source":["# nn.Sequential : 여러 모듈들을 묶어서 사용 가능\n","\n","class NeuralNet2(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        sequential = nn.Sequential(\n","            nn.Linear(input_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, num_classes),\n","            nn.Softmax(dim=1),\n","        )\n","    def forward(self, x):\n","        out = self.sequential(x)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPTW-KP4zy1S","outputId":"cea855e8-e876-4486-a0bd-d7759b12fdd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuralNet(\n","  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n","  (relu): ReLU()\n","  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["input_size = 28*28*1 # MNIST 이미지 크기\n","hidden_size = 100 # hyper parameter\n","num_classes = 10 # 총 class 수\n","\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"xBbxscK4zy1S"},"source":["## 손실 함수"]},{"cell_type":"markdown","metadata":{"id":"h76x-deQzy1T"},"source":["### Cross Entropy"]},{"cell_type":"markdown","metadata":{"id":"ihSB4QvFzy1T"},"source":["Binary Cross Entropy Loss (nn.BCELoss())\n","- Binary Class (0/1)에 적용\n","- Loss 적용 전 sigmoid나 softmax를 취해줘야 함"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdZSOE-1zy1T"},"outputs":[],"source":["x = torch.randn(3)\n","y = torch.tensor([0.,1.,0.]) # binary 이므로 target(y) 값은 0 또는 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13AzrYe0zy1T","outputId":"e4c2d075-82fe-43a7-aa4c-c2942b8e86be"},"outputs":[{"name":"stdout","output_type":"stream","text":["x: tensor([-0.7477,  0.4827,  0.6035])\n","y: tensor([0., 1., 0.])\n"]}],"source":["print('x:',x)\n","print('y:',y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sh5irULRzy1T","outputId":"4f910b06-b597-4e60-f7fb-0b67b81fb095"},"outputs":[{"name":"stdout","output_type":"stream","text":["binary cross entropy loss value: tensor(0.6360)\n"]}],"source":["# Binary Cross Entropy Loss\n","bce_loss = nn.BCELoss()\n","sigmoid = nn.Sigmoid()\n","\n","x_sigmoid = sigmoid(x)\n","print('binary cross entropy loss value:', bce_loss(x_sigmoid,y))"]},{"cell_type":"markdown","metadata":{"id":"BzUMOz8Pzy1T"},"source":["Binary Cross Entropy With Logits Loss (nn.BCEWithLogitsLoss())\n","- Binary Class (0/1)에 적용\n","- Loss안에 Sigmoid가 내장되어있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-iOpvn7ezy1U","outputId":"b8d9d97c-69ad-4808-8b86-42769528269e"},"outputs":[{"name":"stdout","output_type":"stream","text":["binary cross entropy loss value: tensor(0.6360)\n"]}],"source":["# Binary Cross Entropy Loss\n","bce_with_logits_loss = nn.BCEWithLogitsLoss()\n","\n","print('binary cross entropy loss value:', bce_with_logits_loss(x,y))"]},{"cell_type":"markdown","metadata":{"id":"jvZ1Be0Pzy1U"},"source":["Cross Entropy Loss (nn.CrossEntropyLoss())\n","- Multi Class에서 적용\n","- Loss안에 Softmax가 내장되어 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"It-Yd0n8zy1U"},"outputs":[],"source":["x = torch.randn(1,10)\n","y = torch.tensor([1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"toJpwN32zy1U","outputId":"4ff8c33d-30c8-4573-85a7-650d1bf3b71f"},"outputs":[{"name":"stdout","output_type":"stream","text":["x: tensor([[-1.3782,  0.8480, -0.1404,  1.0514, -1.0601,  0.1745,  0.1179, -1.1434,\n","         -0.2724, -1.2614]])\n","y: tensor([1])\n"]}],"source":["print('x:',x)\n","print('y:',y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDNmIRmazy1U","outputId":"371f4474-7837-46ed-a819-8a3802a2c40c"},"outputs":[{"name":"stdout","output_type":"stream","text":["cross_entropy loss value: tensor(1.4884)\n"]}],"source":["# Cross Entropy Loss\n","\n","cross_entropy_loss = nn.CrossEntropyLoss()\n","# Softmax와 Log를 한 후 Cross Entropy Loss\n","\n","print('cross_entropy loss value:', cross_entropy_loss(x,y))"]},{"cell_type":"markdown","metadata":{"id":"kCTHCAHdzy1V"},"source":["### MSE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5T4Da4Gzy1V"},"outputs":[],"source":["x = torch.randn(1,10)  # 리그레션에 해당하는 loss이기에 꼭 정수일 필요없다.\n","y = torch.randn(1,10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"et2HP1VKzy1V","outputId":"4876e7a8-026a-4bd9-9ccb-46948b0f1549"},"outputs":[{"name":"stdout","output_type":"stream","text":["cross_entropy loss value: tensor(1.4131)\n"]}],"source":["mse_loss = nn.MSELoss()\n","print('cross_entropy loss value:', mse_loss(x,y))"]}],"metadata":{"kernelspec":{"display_name":"minkyu","language":"python","name":"minkyu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}